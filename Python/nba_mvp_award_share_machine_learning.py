# -*- coding: utf-8 -*-
"""NBA-MVP-Award-Share-Machine-Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GznYuGo34GOvgtLe2_beRDqqfww0JDtJ
"""

from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from google.colab import drive # Import only if you are using Google Colab

df_train = pd.read_csv('df_1980_2020.csv', sep = ',', decimal = '.')

df_train.info()

df_train['Wins'] = df_train.Overall.apply(lambda x: x.split('-')[0]).astype(int)
df_train['Losses'] = df_train.Overall.apply(lambda x: x.split('-')[1]).astype(int)
df_train['W/L%'] = df_train.Wins / (df_train.Wins + df_train.Losses)

df_train['GS%'] = df_train.GS / df_train.G
df_train['GP%'] = df_train.G / (df_train.Wins + df_train.Losses)

df_train['MVP Rank'] = df_train.groupby('Season')['Pts Won'].rank(ascending = False, method = 'dense')
df_train['Won MVP'] = np.where(df_train['MVP Rank'] == 1, 1, 0)

df_train.tail()

corr = df_train.corr(method = 'pearson')
won_mvp_corr = corr[['Won MVP']]
won_mvp_corr['Won MVP'].abs().sort_values()

df_train.Player.count()

df_train_filtered = df_train[df_train['Pts Won'] > 0]
df_train_filtered.Player.count()

corr = df_train_filtered.corr(method = 'pearson')
won_mvp_corr = corr[['Won MVP']]
won_mvp_corr['Won MVP'].abs().sort_values()

def plot_two_variables(df, title, var1, var1_order, var2, var2_order):
    plt.style.use('fivethirtyeight')
    fig, ax = plt.subplots()

    mvp = df[df['Won MVP'] == 1]
    non_mvp = df[df['Won MVP'] != 1]

    ax.scatter(mvp[var1], mvp[var2], label = 'MVP', marker = '^', s = 100)
    ax.scatter(non_mvp[var1], non_mvp[var2], label = 'Not MVP', alpha = .2)

    ax.legend(loc = 'best', prop = {'size': 12})

    ax.set_xlabel(var1, fontsize = 16)
    ax.set_ylabel(var2, fontsize = 16)

    ax.set_xlim(ax.get_xlim()[::var1_order])
    ax.set_ylim(ax.get_ylim()[::var2_order])

    fig.suptitle(title, weight = 'bold', size = 20)

    fig.text(x = -0.02, y = -0.08,
        s = '_______________________________________________________',
        fontsize = 16, color = 'grey', horizontalalignment = 'left', alpha = .2)

    fig.text(x = -0.02, y = -0.16,
        s = 'https://devcbc.github.io',
        fontsize = 16, color = 'grey', horizontalalignment = 'left')

plot_two_variables(df_train_filtered, 'Player Win Share VS Team Overall Seed', 'Rk', -1, 'WS', 1)

df_train_filtered[(df_train_filtered['Won MVP'] == 1) & (df_train_filtered['Rk'] > 5)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

plot_two_variables(df_train_filtered, 'Points Per Game VS Efficiency Rating', 'PTS', 1, 'PER', 1)

df_train_filtered[(df_train_filtered['Won MVP'] == 1) & (df_train_filtered['PTS'] <= 20)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

plot_two_variables(df_train_filtered, 'Team Overall Seed VS Player Value of Replacement', 'Rk', -1, 'VORP', 1)

def build_features(df_train, df_test):
    mms = MinMaxScaler()

    x_train_mms = mms.fit_transform(df_train[['ORB%', 'ORB', 'BLK%', 'FTr', 'Age', 'TOV%', '3P%', '3PAr', 'BLK', 'STL%', 'GS', 'TRB%',
                                              'STL', 'FG%', '3PA', 'DRB%', 'G', '3P', 'TRB', 'FT%', '2P%', 'AST', 'PF', 'MP',
                                              'eFG%', 'DRB', 'AST%', '2PA', 'TOV', 'TS%', '2P', 'FTA', 'FGA', 'USG%', 'DBPM', 'FT',
                                              'DWS', 'FG', 'PTS', 'Rk', 'OBPM', 'OWS', 'PER', 'BPM', 'WS/48', 'VORP', 'WS',
                                              'Wins', 'Losses', 'W/L%', 'GS%', 'GP%']])

    x_test_mms = mms.transform(df_test[['ORB%', 'ORB', 'BLK%', 'FTr', 'Age', 'TOV%', '3P%', '3PAr', 'BLK', 'STL%', 'GS', 'TRB%',
                                        'STL', 'FG%', '3PA', 'DRB%', 'G', '3P', 'TRB', 'FT%', '2P%', 'AST', 'PF', 'MP',
                                        'eFG%', 'DRB', 'AST%', '2PA', 'TOV', 'TS%', '2P', 'FTA', 'FGA', 'USG%', 'DBPM', 'FT',
                                        'DWS', 'FG', 'PTS', 'Rk', 'OBPM', 'OWS', 'PER', 'BPM', 'WS/48', 'VORP', 'WS',
                                        'Wins', 'Losses', 'W/L%', 'GS%', 'GP%']])

    x_train = np.hstack([x_train_mms])
    x_test = np.hstack([x_test_mms])

    y_train = df_train['Won MVP'].values.reshape(-1, 1)
    y_test = df_test['Won MVP'].values.reshape(-1, 1)

    return x_train, y_train, x_test, y_test

model = LogisticRegression(solver = 'liblinear')

df_train_predicted = []
results_matrix = np.zeros(shape = (1, 2020 - 1980, 4, 2))
for season in range(1980, 2021):
    fold = season - 1980 - 1
    df_train = df_train_filtered[df_train_filtered.Season != season]
    df_test = df_train_filtered[df_train_filtered.Season == season]

    x_train, y_train, x_test, y_test = build_features(df_train, df_test)

    model.fit(x_train, y_train)

    df_train_rank = df_train.copy()
    df_train_rank['MVP Odds'] = model.predict_proba(x_train)[:, 1]

    df_train_rank['Predicted MVP Rank'] = df_train_rank.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')

    df_train_rank['Predicted MVP Winner'] = df_train_rank['Predicted MVP Rank']
    df_train_rank['Predicted MVP Winner'].loc[df_train_rank['Predicted MVP Winner'] != 1] = 0

    df_train_rank_won_mvp = df_train_rank['Won MVP']
    df_train_rank_predicted_mvp_winner = df_train_rank['Predicted MVP Winner']

    results_matrix[0, fold, 0, 0] = metrics.accuracy_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 1, 0] = metrics.precision_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 2, 0] = metrics.recall_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 3, 0] = metrics.f1_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)

    df_test_rank = df_test.copy()
    df_test_rank['MVP Odds'] = model.predict_proba(x_test)[:, 1]

    df_train_predicted.append(df_test_rank)

    df_test_rank['Predicted MVP Rank'] = df_test_rank.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')

    df_test_rank['Predicted MVP Winner'] = df_test_rank['Predicted MVP Rank']
    df_test_rank['Predicted MVP Winner'].loc[df_test_rank['Predicted MVP Winner'] != 1] = 0

    df_test_rank_won_mvp = df_test_rank['Won MVP']
    df_test_rank_predicted_mvp_winner = df_test_rank['Predicted MVP Winner']

    results_matrix[0, fold, 0, 1] = metrics.accuracy_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 1, 1] = metrics.precision_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 2, 1] = metrics.recall_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 3, 1] = metrics.f1_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)

print('Algorithm: Logistic Regression')
print()
print('Train')
print('Accuracy:', results_matrix[0, :, 0, 0].mean())
print('Precision:', results_matrix[0, :, 1, 0].mean())
print('Coverage:', results_matrix[0, :, 2, 0].mean())
print('F Measure:', results_matrix[0, :, 3, 0].mean())
print()
print('Test')
print('Accuracy:', results_matrix[0, :, 0, 1].mean())
print('Precision:', results_matrix[0, :, 1, 1].mean())
print('Coverage:', results_matrix[0, :, 2, 1].mean())
print('F Measure:', results_matrix[0, :, 3, 1].mean())

df_train_predicted = pd.concat(df_train_predicted)

df_train_predicted[(df_train_predicted['Won MVP'] == 1) & (df_train_predicted['Predicted MVP Winner'] != 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'Predicted MVP Rank']]

df_train_predicted[(df_train_predicted['Won MVP'] != 1) & (df_train_predicted['Predicted MVP Winner'] == 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'MVP Rank']]

df_train_predicted[(df_train_predicted['Won MVP'] == 1) & (df_train_predicted['Predicted MVP Winner'] == 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

predicted = df_train_predicted['Predicted MVP Winner']
ground_truth = df_train_predicted['Won MVP']

cm = confusion_matrix(ground_truth, predicted)

plt.title('Confusion Matrix - MVP Prediction')
sns.heatmap(cm, annot = True, fmt = '.2f', cmap = 'rocket_r')

plt.text(x = -0.02, y = 2.16,
    s = '_______________________________________________________',
    fontsize = 16, color = 'grey', horizontalalignment = 'left', alpha = .2)

plt.text(x = -0.02, y = 2.32,
    s = 'https://devcbc.github.io',
    fontsize = 16, color = 'grey', horizontalalignment = 'left')

plt.show()

df_production = pd.read_csv('df_2021.csv', sep = ',', decimal = '.')

df_production['Wins'] = df_production.Overall.apply(lambda x: x.split('-')[0]).astype(int)
df_production['Losses'] = df_production.Overall.apply(lambda x: x.split('-')[1]).astype(int)
df_production['W/L%'] = df_production.Wins / (df_production.Wins + df_production.Losses)

df_production['GS%'] = df_production.GS / df_production.G
df_production['GP%'] = df_production.G / (df_production.Wins + df_production.Losses)

df_production['Won MVP'] = 0

df_production.Player.count()

df_production = df_production[(df_production['GS%'] > 0.9) & (df_production['GP%'] > 0.7)]

df_production.Player.count()

x_train, y_train, x_test, y_test = build_features(df_train_filtered, df_production)
x_complete = x_train
y_complete = y_train

model.fit(x_complete, y_complete)

df_production['MVP Odds'] = model.predict_proba(x_test)[:, 1]

df_production['Predicted MVP Rank'] = df_production.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')

df_production['Predicted MVP Winner'] = df_production['Predicted MVP Rank']
df_production['Predicted MVP Winner'].loc[df_production['Predicted MVP Winner'] != 1] = 0

df_production.sort_values(by = ['Predicted MVP Rank'], ascending = True)[['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'MVP Odds']].head(10)